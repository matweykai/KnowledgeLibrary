ContrastiveLoss - это семейство функций потерь, которое используется в задачах
		  metric learning и face recognition. Они позволяют обучать
		  модели в unsupervised стиле

* Данное понятие дал Ян Лекун в 2005 году, когда он пытался придумать решение
  для задачи снижения размерности. Он хотел максимально сохранить отношения
  между векторами в новом пространстве, те близкие вектора должны остаться
  близкими, а далёкие - далёкими

* Позже его подход перерос в семейство функций потерь, которые теперь
  используются во многих задачах

* Ян Лекун успешно продемострировал работу данного лосса в задаче MNIST

Общая формула:

	L(W, (Y, X1, X2)_i) = (1 - Y) * L_s(D_i_w) + Y * L_d(D_i_w)

	- Первое слагаемое отвечает за близкие вектора
	- Второе слагаемое отвечает за дальние вектора

Формула Яна Лекуна:

	L(W, Y, X1, X2) = (1 - Y) / 2 (D_w)^2 + Y * max(0, m - D_w) / 2

	- Первое слагаемое старается приблизить похожие вектора
	- Второе слагаемое старается вынести непохожие вектора на радиус m

* Ян Лекун использовал зазор m, для того, чтобы потом эффективно применять KNN
  и находить соседей в фиксированном радиусе

Полезные ссылки:
 - https://medium.com/@maksym.bekuzarov/losses-explained-contrastive-loss-f8f57fe32246
