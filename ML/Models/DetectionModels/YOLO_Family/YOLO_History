* Семейство моделей YOLO пришло на замену RCNN, чтобы ускорить детекцию

* Главным отличием YOLO является одностадийный процесс детекции, при котором
  используется меньшее число вычислений

YOLOv1 - 2015 год
 - её качество на VOC датасете было лучше чем RCNN (59.2 AP против 54.2)

 - а скорость была 45 fps, а RCNN тратила несколько секунд на одно изображение

 - Состоит из 3 блоков: backbone, neck и head. Для каждой ячейки изображения 
   вычисляются Bounding Box'ы. (Остальное в разделе о YOLOv1)

YOLOv2 - 2016 год
 - данное улучшение имеет альтернативное имя YOLO9000, потому что могло находить
   9000 классов
  
 - к значительному увеличению качества привело использование Anchor Boxes, они
   вычисляются по обучающей выборке с использованием кластеризации label box'ов
   Скорость достигла 200 FPS(+155) при mAP 75.3(+16.1)

 - при обучении использовался multi-scale training, а также данные из ImageNet
   датасета. Тк в нём нет меток для BB, то там использовался только loss для
   классификации

YOLOv3 - 2018 год
 - из модели убрали линейные и pooling слои, что снизило её размер и вес

 - начали использовать FPN и resnet модели

 - в качестве backbone начали использовать Darknet архитектуры

YOLOv4 - 2020 год
 - применяются новые оптимизации Bag of Freebies (для улучшения качества модели
   без увеличения вычислительной сложности) и Bag of Specials (улучшение 
   точности с потерей скорости)

 - BOS привнёс в модель пространственный механизм внимания

 - точность вырастает до 43.5 mAP на COCO, что больше на 15.3 пункта 
   относительно YOLOv3

YOLOv5 - 2020 год
 - перенос модели YOLOv3 на PyTorch от компании ultralytics

 - применяются более оптимальные loss функции, аугментации данных

Статьи:
 - https://machinelearningknowledge.ai/a-brief-history-of-yolo-object-detection-models/
 - https://dataphoenix.info/a-guide-to-the-yolo-family-of-computer-vision-models/

