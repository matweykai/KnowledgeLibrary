MultiLabelClassification - это задача машинного обучения, в которой мы должны
	предсказать одному объекту несколько меток, например жанры для фильма
	или книги по их описанию

* Данная постановка задачи отличается от Multiclass задачи тем, что тут наличие
  одного класса не исключает другого. Хотя и в той и в другой задаче применяется
  One-vs-Rest подход, но его выходы интерпретируются по-разному

* Для данной задачи есть свои метрики, которые учитывают, что предсказать 4 из 5
  меток лучше, чем не отгадать ни одной

Метрики:
	HammingLoss:
	
		HL = 1 / (|N| * |L|) * sum(sum(xor(gt_i_j, pr_i_j)) {j: 1 до L} ) {i: 1 до N}
	
	* Такая метрика учитывает вклад каждой правильно предсказанной метки


	ExactMatchRatio:

		MR = 1 / N * sum( GT_i == PR_I ) {i: 1 до N}

	* Это метрика направлена на полное совпадение меток и не учитывает
	  правильно предсказанных подмножеств

Подходы к решению задачи:

	OneVsRest - данный подход ориентирован на обучение независимых 
		классификаторов, которые отвечают за свой класс. А потом они
		используются в итоговом предсказании

	* Такой подход не учитывает корреляцию классов, которая очень часто 
	  присутствует (детектив + драма, фантастика + приключения)


	BinaryRelevance - эта техника аналогична OneVsRest, просто её 
		употребляют в контексте multi label задач

	
	ClassifierChains - подход к задаче, который учитывает корреляцию 
		меток

	* В данном методе обучается классификатор для C1, потом к данным 
	  добавляется ответы C1 на тренировочных данных и обучается C2 на этом
	  наборе и тд

	* Данный метод основан на умножения вероятностей для нескольких событий
	  или так называемом Chain Rule


	LabelPowerSet - подход, в котором для каждого подмножества меток
		создаётся свой классификатор, и обучается находить именно это
		подмножество

	Пример: a1 = {C1, C2, C3}, a2 = {C1, C2}, a3 = {C3}, a4 = {C1, C2}
		В данном случае мы будем обучать 3 классификатора:
			M1 определяет {0, {C1, C2, C3}}
			M2 определяет {0, {C1, C2}}
			M3 определяет {0, {C3}}

	* Данный метод наименее распространён, тк является вычислительно
	  сложным и с ростом кол-ва классов кол-во вычислений растёт 
	  экспоненциально. Также есть проблема маленького кол-ва примеров для
	  некоторых редких комбинаций меток

	* В худшем случае мы будем обучать 2^С классификаторов

	
	Подстраивание моделей - в данном случае меняется внутренняя начинка 
		модели, применяются другие функции потерь(например кросс 
		энтропия, а не логистическая функция потерь)

Решение задачи в DL:

	* Для решения задачи multi-label достаточно использовать binary 
	  cross-entropy loss, а при inference к выходам модели применять
	  сигмоиду

Статьи:
 - https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff
 - https://www.youtube.com/watch?v=vnObmjMWVd0
 - https://machinelearningmastery.com/multi-label-classification-with-deep-learning/
